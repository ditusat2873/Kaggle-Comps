{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34377,"databundleVersionId":3220602,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:35:10.638608Z","iopub.execute_input":"2025-06-22T23:35:10.638903Z","iopub.status.idle":"2025-06-22T23:35:10.743150Z","shell.execute_reply.started":"2025-06-22T23:35:10.638885Z","shell.execute_reply":"2025-06-22T23:35:10.742319Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/spaceship-titanic/sample_submission.csv\n/kaggle/input/spaceship-titanic/train.csv\n/kaggle/input/spaceship-titanic/test.csv\n","output_type":"stream"}],"execution_count":149},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntrain_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:35:11.554353Z","iopub.execute_input":"2025-06-22T23:35:11.555157Z","iopub.status.idle":"2025-06-22T23:35:11.598348Z","shell.execute_reply.started":"2025-06-22T23:35:11.555133Z","shell.execute_reply":"2025-06-22T23:35:11.597471Z"}},"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n\n   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n\n   Transported  \n0        False  \n1         True  \n2        False  \n3        False  \n4         True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>B/0/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>39.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Maham Ofracculy</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>24.0</td>\n      <td>False</td>\n      <td>109.0</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>549.0</td>\n      <td>44.0</td>\n      <td>Juanna Vines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>58.0</td>\n      <td>True</td>\n      <td>43.0</td>\n      <td>3576.0</td>\n      <td>0.0</td>\n      <td>6715.0</td>\n      <td>49.0</td>\n      <td>Altark Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003_02</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>33.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1283.0</td>\n      <td>371.0</td>\n      <td>3329.0</td>\n      <td>193.0</td>\n      <td>Solam Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/1/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>False</td>\n      <td>303.0</td>\n      <td>70.0</td>\n      <td>151.0</td>\n      <td>565.0</td>\n      <td>2.0</td>\n      <td>Willy Santantines</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":150},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\ntest_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:35:12.484606Z","iopub.execute_input":"2025-06-22T23:35:12.485441Z","iopub.status.idle":"2025-06-22T23:35:12.516547Z","shell.execute_reply.started":"2025-06-22T23:35:12.485415Z","shell.execute_reply":"2025-06-22T23:35:12.515728Z"}},"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n\n   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013_01</td>\n      <td>Earth</td>\n      <td>True</td>\n      <td>G/3/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>27.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Nelly Carsoning</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0018_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/4/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>19.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>2823.0</td>\n      <td>0.0</td>\n      <td>Lerome Peckers</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0019_01</td>\n      <td>Europa</td>\n      <td>True</td>\n      <td>C/0/S</td>\n      <td>55 Cancri e</td>\n      <td>31.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Sabih Unhearfus</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0021_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>C/1/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>38.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>6652.0</td>\n      <td>0.0</td>\n      <td>181.0</td>\n      <td>585.0</td>\n      <td>Meratz Caltilter</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0023_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/5/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>20.0</td>\n      <td>False</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>635.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Brence Harperez</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":151},{"cell_type":"code","source":"samp = pd.read_csv(\"/kaggle/input/spaceship-titanic/sample_submission.csv\")\nsamp.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:35:14.461938Z","iopub.execute_input":"2025-06-22T23:35:14.462234Z","iopub.status.idle":"2025-06-22T23:35:14.476053Z","shell.execute_reply.started":"2025-06-22T23:35:14.462212Z","shell.execute_reply":"2025-06-22T23:35:14.475300Z"}},"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"  PassengerId  Transported\n0     0013_01        False\n1     0018_01        False\n2     0019_01        False\n3     0021_01        False\n4     0023_01        False","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0018_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0019_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0021_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0023_01</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":152},{"cell_type":"code","source":"counts = train_data['Transported'].value_counts()\nprint(\"Counts:\\n\", counts)\nfreqs = train_data['Transported'].value_counts(normalize=True)\nprint(\"\\nPercentages:\\n\", freqs * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:35:14.763102Z","iopub.execute_input":"2025-06-22T23:35:14.763449Z","iopub.status.idle":"2025-06-22T23:35:14.771426Z","shell.execute_reply.started":"2025-06-22T23:35:14.763419Z","shell.execute_reply":"2025-06-22T23:35:14.770513Z"}},"outputs":[{"name":"stdout","text":"Counts:\n Transported\nTrue     4378\nFalse    4315\nName: count, dtype: int64\n\nPercentages:\n Transported\nTrue     50.362361\nFalse    49.637639\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":153},{"cell_type":"code","source":"#seeing if we have any missing data.\nmissing_counts = train_data.isnull().sum().sort_values(ascending=False)\nmissing_counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:35:16.225743Z","iopub.execute_input":"2025-06-22T23:35:16.226040Z","iopub.status.idle":"2025-06-22T23:35:16.237759Z","shell.execute_reply.started":"2025-06-22T23:35:16.226018Z","shell.execute_reply":"2025-06-22T23:35:16.236847Z"}},"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"CryoSleep       217\nShoppingMall    208\nVIP             203\nHomePlanet      201\nName            200\nCabin           199\nVRDeck          188\nFoodCourt       183\nSpa             183\nDestination     182\nRoomService     181\nAge             179\nPassengerId       0\nTransported       0\ndtype: int64"},"metadata":{}}],"execution_count":154},{"cell_type":"code","source":"def preprocess_data(data):\n    data = data.copy() #just getting a copy\n    def normalize_name(x):\n        if pd.isna(x):\n            return \"Unknown\"\n        parts = str(x).split()\n        return \" \".join(p.strip(' ,().\"\\'') for p in parts)\n\n    def get_title(x):\n        if pd.isna(x):\n            return \"Unknown\"\n        m = re.search(r\",\\s*([^\\.]+)\\.\", x)\n        return m.group(1).strip() if m else \"Unknown\"\n\n    data[\"Name\"] = data[\"Name\"].apply(normalize_name)\n\n    cabin_split = (\n        data[\"Cabin\"]\n          .fillna(\"Unknown/0/X\") # placeholder for missing cabins\n          .astype(str)\n          .str.split(\"/\", expand=True)\n    )\n    cabin_split.columns = [\"Deck\", \"CabinNum\", \"Side\"]\n    cabin_split[\"CabinNum\"] = pd.to_numeric(cabin_split[\"CabinNum\"], errors=\"coerce\")\n    data = pd.concat([data, cabin_split], axis=1)\n\n    \n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:35:16.472254Z","iopub.execute_input":"2025-06-22T23:35:16.472602Z","iopub.status.idle":"2025-06-22T23:35:16.479643Z","shell.execute_reply.started":"2025-06-22T23:35:16.472580Z","shell.execute_reply":"2025-06-22T23:35:16.478731Z"}},"outputs":[],"execution_count":155},{"cell_type":"code","source":"prep_train = preprocess_data(train_data)\nprep_test = preprocess_data(test_data)\n\nprep_train.drop(columns=[\"Cabin\"], inplace=True)\nprep_test.drop(columns=[\"Cabin\"], inplace=True)\n#now maybe try to one hot encode cryosleep and VIP\ndef ohe_data(data):\n    data[\"CryoSleep\"] = data[\"CryoSleep\"].map({True:1, False:0})\n    data[\"VIP\"]       = data[\"VIP\"].map({True:1, False:0})\n    return data\nohe_train = ohe_data(prep_train)\nohe_test = ohe_data(prep_test)\nohe_train[\"Transported\"] = ohe_train[\"Transported\"].map({True:1, False:0})\nohe_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:35:17.985461Z","iopub.execute_input":"2025-06-22T23:35:17.985778Z","iopub.status.idle":"2025-06-22T23:35:18.060936Z","shell.execute_reply.started":"2025-06-22T23:35:17.985756Z","shell.execute_reply":"2025-06-22T23:35:18.059553Z"}},"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"  PassengerId HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  \\\n0     0001_01     Europa        0.0  TRAPPIST-1e  39.0  0.0          0.0   \n1     0002_01      Earth        0.0  TRAPPIST-1e  24.0  0.0        109.0   \n2     0003_01     Europa        0.0  TRAPPIST-1e  58.0  1.0         43.0   \n3     0003_02     Europa        0.0  TRAPPIST-1e  33.0  0.0          0.0   \n4     0004_01      Earth        0.0  TRAPPIST-1e  16.0  0.0        303.0   \n\n   FoodCourt  ShoppingMall     Spa  VRDeck               Name  Transported  \\\n0        0.0           0.0     0.0     0.0    Maham Ofracculy            0   \n1        9.0          25.0   549.0    44.0       Juanna Vines            1   \n2     3576.0           0.0  6715.0    49.0      Altark Susent            0   \n3     1283.0         371.0  3329.0   193.0       Solam Susent            0   \n4       70.0         151.0   565.0     2.0  Willy Santantines            1   \n\n  Deck  CabinNum Side  \n0    B         0    P  \n1    F         0    S  \n2    A         0    S  \n3    A         0    S  \n4    F         1    S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n      <th>Deck</th>\n      <th>CabinNum</th>\n      <th>Side</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_01</td>\n      <td>Europa</td>\n      <td>0.0</td>\n      <td>TRAPPIST-1e</td>\n      <td>39.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Maham Ofracculy</td>\n      <td>0</td>\n      <td>B</td>\n      <td>0</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002_01</td>\n      <td>Earth</td>\n      <td>0.0</td>\n      <td>TRAPPIST-1e</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>109.0</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>549.0</td>\n      <td>44.0</td>\n      <td>Juanna Vines</td>\n      <td>1</td>\n      <td>F</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003_01</td>\n      <td>Europa</td>\n      <td>0.0</td>\n      <td>TRAPPIST-1e</td>\n      <td>58.0</td>\n      <td>1.0</td>\n      <td>43.0</td>\n      <td>3576.0</td>\n      <td>0.0</td>\n      <td>6715.0</td>\n      <td>49.0</td>\n      <td>Altark Susent</td>\n      <td>0</td>\n      <td>A</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003_02</td>\n      <td>Europa</td>\n      <td>0.0</td>\n      <td>TRAPPIST-1e</td>\n      <td>33.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1283.0</td>\n      <td>371.0</td>\n      <td>3329.0</td>\n      <td>193.0</td>\n      <td>Solam Susent</td>\n      <td>0</td>\n      <td>A</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004_01</td>\n      <td>Earth</td>\n      <td>0.0</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>0.0</td>\n      <td>303.0</td>\n      <td>70.0</td>\n      <td>151.0</td>\n      <td>565.0</td>\n      <td>2.0</td>\n      <td>Willy Santantines</td>\n      <td>1</td>\n      <td>F</td>\n      <td>1</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":156},{"cell_type":"code","source":"#need to split CV set and normal training set!\ntrain_df, val_df = train_test_split(\n    ohe_train, \n    test_size=0.2, \n    random_state=42, \n    stratify=ohe_train[\"Transported\"]\n)\nFEATURE_COLUMNS = [\n    c for c in ohe_train.columns\n    if c not in [\"PassengerId\", \"Name\", \"Transported\"]\n]\n\ndef make_tf_dataset(df, label=True):\n    #makes a tf ds that tf can train on\n    if label:\n        return tfdf.keras.pd_dataframe_to_tf_dataset(\n            df[FEATURE_COLUMNS + [\"Transported\"]],\n            label=\"Transported\",\n            task=tfdf.keras.Task.CLASSIFICATION\n        )\n    else:\n        return tfdf.keras.pd_dataframe_to_tf_dataset(\n            df[FEATURE_COLUMNS],\n            label=None\n        )\n\ntrain_ds = make_tf_dataset(train_df, label=True) \nval_ds   = make_tf_dataset(val_df,   label=True) \ntest_ds  = make_tf_dataset(ohe_test,  label=False)\n\n\nmodel = tfdf.keras.GradientBoostedTreesModel(\n    features=[tfdf.keras.FeatureUsage(name=f) for f in FEATURE_COLUMNS],\n    num_trees=200,\n    max_depth=6,\n    shrinkage=0.1,\n    random_seed=42\n)\n\nmodel.fit(train_ds)\neval_dict = model.evaluate(val_ds, return_dict=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:36:40.497569Z","iopub.execute_input":"2025-06-22T23:36:40.498468Z","iopub.status.idle":"2025-06-22T23:36:42.372047Z","shell.execute_reply.started":"2025-06-22T23:36:40.498440Z","shell.execute_reply":"2025-06-22T23:36:42.371106Z"}},"outputs":[{"name":"stdout","text":"Use /tmp/tmph0_ro_17 as temporary training directory\nReading training dataset...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"name":"stdout","text":"Training dataset read in 0:00:00.360568. Found 6954 examples.\nTraining model...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1750635400.968088      35 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1750635400.968124      35 kernel.cc:783] Collect training examples\nI0000 00:00:1750635400.968137      35 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^HomePlanet$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^CryoSleep$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Destination$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^VIP$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^RoomService$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^FoodCourt$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^ShoppingMall$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Spa$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^VRDeck$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Deck$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^CabinNum$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Side$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: false\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1750635400.968868      35 kernel.cc:401] Number of batches: 7\nI0000 00:00:1750635400.968890      35 kernel.cc:402] Number of examples: 6954\nI0000 00:00:1750635400.970598      35 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Deck (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1750635400.971962      35 kernel.cc:802] Training dataset:\nNumber of records: 6954\nNumber of columns: 14\n\nNumber of columns by type:\n\tNUMERICAL: 9 (64.2857%)\n\tCATEGORICAL: 5 (35.7143%)\n\nColumns:\n\nNUMERICAL: 9 (64.2857%)\n\t0: \"Age\" NUMERICAL num-nas:139 (1.99885%) mean:28.6838 min:0 max:79 sd:14.4964\n\t1: \"CabinNum\" NUMERICAL mean:584.168 min:0 max:1893 sd:512.667\n\t2: \"CryoSleep\" NUMERICAL num-nas:168 (2.41588%) mean:0.358974 min:0 max:1 sd:0.4797\n\t5: \"FoodCourt\" NUMERICAL num-nas:154 (2.21455%) mean:452.611 min:0 max:29813 sd:1602.35\n\t7: \"RoomService\" NUMERICAL num-nas:145 (2.08513%) mean:230.15 min:0 max:14327 sd:676.288\n\t8: \"ShoppingMall\" NUMERICAL num-nas:169 (2.43026%) mean:170.034 min:0 max:12253 sd:548.713\n\t10: \"Spa\" NUMERICAL num-nas:150 (2.15703%) mean:308.868 min:0 max:22408 sd:1142.03\n\t11: \"VIP\" NUMERICAL num-nas:158 (2.27207%) mean:0.0233961 min:0 max:1 sd:0.151158\n\t12: \"VRDeck\" NUMERICAL num-nas:144 (2.07075%) mean:296.65 min:0 max:20336 sd:1108.5\n\nCATEGORICAL: 5 (35.7143%)\n\t3: \"Deck\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (0.0575209%) most-frequent:\"F\" 2228 (32.0391%)\n\t4: \"Destination\" CATEGORICAL num-nas:153 (2.20017%) has-dict vocab-size:4 zero-ood-items most-frequent:\"TRAPPIST-1e\" 4694 (69.0193%)\n\t6: \"HomePlanet\" CATEGORICAL num-nas:169 (2.43026%) has-dict vocab-size:4 zero-ood-items most-frequent:\"Earth\" 3673 (54.1341%)\n\t9: \"Side\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 3412 (49.0653%)\n\t13: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1750635400.972007      35 kernel.cc:818] Configure learner\nI0000 00:00:1750635400.972424      35 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^CabinNum$\"\nfeatures: \"^CryoSleep$\"\nfeatures: \"^Deck$\"\nfeatures: \"^Destination$\"\nfeatures: \"^FoodCourt$\"\nfeatures: \"^HomePlanet$\"\nfeatures: \"^RoomService$\"\nfeatures: \"^ShoppingMall$\"\nfeatures: \"^Side$\"\nfeatures: \"^Spa$\"\nfeatures: \"^VIP$\"\nfeatures: \"^VRDeck$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 42\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 200\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1750635400.972551      35 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmph0_ro_17/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1750635400.972762    3311 kernel.cc:895] Train model\n","output_type":"stream"},{"name":"stdout","text":"Model trained in 0:00:01.005431\nCompiling model...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1750635401.917810    3311 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.794082\nI0000 00:00:1750635401.925970    3311 kernel.cc:926] Export model in log directory: /tmp/tmph0_ro_17 with prefix 0dfb9c67876c40db\nI0000 00:00:1750635401.930153    3311 kernel.cc:944] Save model in resources\nI0000 00:00:1750635401.931976      35 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.794082\n\nAccuracy: 0.788301  CI95[W][0 1]\nErrorRate: : 0.211699\n\n\nConfusion Table:\ntruth\\prediction\n     1    2\n1  263   87\n2   65  303\nTotal: 718\n\n\nI0000 00:00:1750635401.966816      35 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\nI0000 00:00:1750635401.967605      35 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","output_type":"stream"},{"name":"stdout","text":"Model compiled.\n2/2 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n","output_type":"stream"}],"execution_count":158},{"cell_type":"code","source":"probs = model.predict(test_ds) \np_transport = probs.squeeze()\npreds = (p_transport >= 0.5)\n\nsubmission = pd.DataFrame({\n    \"PassengerId\": ohe_test[\"PassengerId\"],\n    \"Transported\": preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T23:39:18.162026Z","iopub.execute_input":"2025-06-22T23:39:18.162334Z","iopub.status.idle":"2025-06-22T23:39:18.280708Z","shell.execute_reply.started":"2025-06-22T23:39:18.162316Z","shell.execute_reply":"2025-06-22T23:39:18.280021Z"}},"outputs":[{"name":"stdout","text":"5/5 [==============================] - 0s 6ms/step\n","output_type":"stream"}],"execution_count":162},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}